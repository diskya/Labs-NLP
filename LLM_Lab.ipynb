{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-abf55a1e-b644-944f-8c5a-4a9295e4e99a\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"我是通义千问，由阿里云开发的AI助手。我可以回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\",\"refusal\":null,\"role\":\"assistant\",\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1737703374,\"model\":\"qwen2-72b-instruct\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":33,\"prompt_tokens\":22,\"total_tokens\":55,\"completion_tokens_details\":null,\"prompt_tokens_details\":null}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"), \n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen2-72b-instruct\", \n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}],\n",
    "    )\n",
    "    \n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-c1bf6be9-85dc-9fa0-950a-a74f0943d172\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"根据提供的信息，唐纳德·特朗普在2025年1月20日宣誓就任美国第47任总统，开始他的第二任期。因此，按照这个情况，现届美国总统是唐纳德·特朗普。\\n\\n不过，请注意现实时间线上的事件可能与给定的假设情景不同。在实际历史上，唐纳德·特朗普的第一任期是在2017年至2021年，而他的继任者乔·拜登从2021年开始担任美国总统。如果当前时间是2025年1月24日，那么根据现实世界的时间线，乔·拜登应该是现任总统。但根据您给出的信息，在这个设定中特朗普再次当选为总统。\",\"refusal\":null,\"role\":\"assistant\",\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1737700375,\"model\":\"qwen-plus\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":153,\"prompt_tokens\":556,\"total_tokens\":709,\"completion_tokens_details\":null,\"prompt_tokens_details\":{\"audio_tokens\":null,\"cached_tokens\":0}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"), \n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 填写DashScope服务的base_url\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '现届美国总统是谁？'}],\n",
    "    extra_body={\n",
    "        \"enable_search\": True\n",
    "    }\n",
    "    )\n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-be179c84-df81-993a-9545-e7363ae0124e\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"这篇文章是一份自我介绍，主要介绍了名叫孔彦的候选人他的个人背景和专业经验。孔彦拥有接近18年的工作经验，主要集中在外贸电商行业的网站开发运营、企业的数字化转型以及IT技术支持领域。他对AI领域特别感兴趣，并在过去的一年多时间里深入学习了AI的理论和应用。\\n\\n孔彦分享了两个他参与的重要AI相关项目：\\n\\n1. **基于AI Agent的智能助理**：他使用MemGPT框架开发了一个能够理解自然语言指令并与环境互动的智能助理。此项目利用了RAG（检索增强生成）和Function Call技术，并且通过强化学习来增强智能体的功能，使其可以更好地服务于企业知识库的应用场景。\\n\\n2. **大数据分析项目**：在这个项目中，他在高性能计算（HPC）平台上运用Apache Spark进行了数据清洗和ETL（抽取、转换、加载）处理，并采用MLlib库来进行业务数据预测和产品推荐等任务。\\n\\n此外，孔彦还提到了自己在机器学习方面的学习经历，包括亲手实现GPT-2模型代码及从前馈神经网络的基础开始构建模型，同时也熟悉如Pytorch这样的主流深度学习框架。\\n\\n总之，这份自我介绍展示了孔彦丰富的行业经验和对新兴技术如人工智能领域的深刻理解和实践能力。\",\"refusal\":null,\"role\":\"assistant\",\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1737705089,\"model\":\"qwen-long\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":266,\"prompt_tokens\":330,\"total_tokens\":596,\"completion_tokens_details\":null,\"prompt_tokens_details\":null}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "file_object = client.files.create(file=Path(\"自我介绍_孔彦.docx\"), purpose=\"file-extract\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-long\",\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': f'fileid://{file_object.id}'},\n",
    "        {'role': 'user', 'content': '这篇文章讲了什么？'}\n",
    "    ]\n",
    ")\n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第1轮大模型输出信息：{'id': 'chatcmpl-65e5f892-469c-9eb7-b26d-bffc189598ab', 'choices': [{'finish_reason': 'tool_calls', 'index': 0, 'logprobs': None, 'message': {'content': '', 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'call_29d97a05dad7470db4ea82', 'function': {'arguments': '{}', 'name': 'get_current_time'}, 'type': 'function', 'index': 0}]}}], 'created': 1737704250, 'model': 'qwen-plus', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 13, 'prompt_tokens': 221, 'total_tokens': 234, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}}\n",
      "\n",
      "工具输出信息：当前时间：2025-01-24 07:37:29。\n",
      "\n",
      "------------------------------------------------------------\n",
      "第2轮大模型输出信息：{'content': '', 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'call_6f016525fd324c818c304c', 'function': {'arguments': '{\"location\": \"北京市\"}', 'name': 'get_current_weather'}, 'type': 'function', 'index': 0}]}\n",
      "\n",
      "工具输出信息：北京市今天是雨天。 \n",
      "\n",
      "------------------------------------------------------------\n",
      "第3轮大模型输出信息：{'content': '现在北京的时间是2025年1月24日 07:37:29，现在的天气情况为雨天。请带好雨具再出门。', 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "最终答案：现在北京的时间是2025年1月24日 07:37:29，现在的天气情况为雨天。请带好雨具再出门。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 填写DashScope SDK的base_url\n",
    ")\n",
    "\n",
    "# 定义工具列表，模型在选择使用哪个工具时会参考工具的name和description\n",
    "tools = [\n",
    "    # 工具1 获取当前时刻的时间\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"当你想知道现在的时间时非常有用。\",\n",
    "            # 因为获取当前时间无需输入参数，因此parameters为空字典\n",
    "            \"parameters\": {}\n",
    "        }\n",
    "    },  \n",
    "    # 工具2 获取指定城市的天气\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"当你想查询指定城市的天气时非常有用。\",\n",
    "            \"parameters\": {  \n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    # 查询天气时需要提供位置，因此参数设置为location\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"城市或县区，比如北京市、杭州市、余杭区等。\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"location\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 模拟天气查询工具。返回结果示例：“北京今天是雨天。”\n",
    "def get_current_weather(location):\n",
    "    return f\"{location}今天是雨天。 \"\n",
    "\n",
    "# 查询当前时间的工具。返回结果示例：“当前时间：2024-04-15 17:15:18。“\n",
    "def get_current_time():\n",
    "    # 获取当前日期和时间\n",
    "    current_datetime = datetime.now()\n",
    "    # 格式化当前日期和时间\n",
    "    formatted_time = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # 返回格式化后的当前时间\n",
    "    return f\"当前时间：{formatted_time}。\"\n",
    "\n",
    "# 封装模型响应函数\n",
    "def get_response(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-plus\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "        )\n",
    "    return completion.model_dump()\n",
    "\n",
    "assistant_output = \"\"\n",
    "\n",
    "def call_with_messages():\n",
    "    global assistant_output\n",
    "    print('\\n')\n",
    "    messages = [\n",
    "            {\n",
    "                \"content\": \"北京现在的时间和天气？\",\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "    ]\n",
    "    print(\"-\"*60)\n",
    "    # 模型的第一轮调用\n",
    "    i = 1\n",
    "    first_response = get_response(messages)\n",
    "    assistant_output = first_response['choices'][0]['message']\n",
    "    print(f\"\\n第{i}轮大模型输出信息：{first_response}\\n\")\n",
    "    if  assistant_output['content'] is None:\n",
    "        assistant_output['content'] = \"\"\n",
    "    messages.append(assistant_output)\n",
    "    # 如果不需要调用工具，则直接返回最终答案\n",
    "    if assistant_output['tool_calls'] == None:  # 如果模型判断无需调用工具，则将assistant的回复直接打印出来，无需进行模型的第二轮调用\n",
    "        print(f\"无需调用工具，我可以直接回复：{assistant_output['content']}\")\n",
    "        return\n",
    "    # 如果需要调用工具，则进行模型的多轮调用，直到模型判断无需调用工具\n",
    "    while assistant_output['tool_calls'] != None:\n",
    "        # 如果判断需要调用查询天气工具，则运行查询天气工具\n",
    "        if assistant_output['tool_calls'][0]['function']['name'] == 'get_current_weather':\n",
    "            tool_info = {\"name\": \"get_current_weather\", \"role\":\"tool\"}\n",
    "            # 提取位置参数信息\n",
    "            location = json.loads(assistant_output['tool_calls'][0]['function']['arguments'])['location']\n",
    "            tool_info['content'] = get_current_weather(location)\n",
    "        # 如果判断需要调用查询时间工具，则运行查询时间工具\n",
    "        elif assistant_output['tool_calls'][0]['function']['name'] == 'get_current_time':\n",
    "            tool_info = {\"name\": \"get_current_time\", \"role\":\"tool\"}\n",
    "            tool_info['content'] = get_current_time()\n",
    "        print(f\"工具输出信息：{tool_info['content']}\\n\")\n",
    "        print(\"-\"*60)\n",
    "        messages.append(tool_info)\n",
    "        assistant_output = get_response(messages)['choices'][0]['message']\n",
    "        if  assistant_output['content'] is None:\n",
    "            assistant_output['content'] = \"\"\n",
    "        messages.append(assistant_output)\n",
    "        i += 1\n",
    "        print(f\"第{i}轮大模型输出信息：{assistant_output}\\n\")\n",
    "    print(f\"最终答案：{assistant_output['content']}\")\n",
    "\n",
    "\n",
    "call_with_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型输出：欢迎光临百炼手机商店，您需要购买什么尺寸的手机呢？\n",
      "\n",
      "模型输出：我已了解您的购买意向，请稍等。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def get_response(messages):\n",
    "    client = OpenAI(\n",
    "        # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(model=\"qwen-plus\", messages=messages)\n",
    "    return completion\n",
    "\n",
    "# 初始化一个 messages 数组\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"你是一名百炼手机商店的店员，你负责给用户推荐手机。手机有两个参数：屏幕尺寸（包括6.1英寸、6.5英寸、6.7英寸）、分辨率（包括2K、4K）。\n",
    "        你一次只能向用户提问一个参数。如果用户提供的信息不全，你需要反问他，让他提供没有提供的参数。如果参数收集完成，你要说：我已了解您的购买意向，请稍等。\"\"\",\n",
    "    }\n",
    "]\n",
    "assistant_output = \"欢迎光临百炼手机商店，您需要购买什么尺寸的手机呢？\"\n",
    "print(f\"模型输出：{assistant_output}\\n\")\n",
    "while \"我已了解您的购买意向\" not in assistant_output:\n",
    "    user_input = input(\"请输入：\")\n",
    "    # 将用户问题信息添加到messages列表中\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    assistant_output = get_response(messages).choices[0].message.content\n",
    "    # 将大模型的回复信息添加到messages列表中\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_output})\n",
    "    print(f\"模型输出：{assistant_output}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "流式输出内容为：\n",
      "\n",
      "我是\n",
      "来自\n",
      "阿里\n",
      "云的大规模语言\n",
      "模型，我叫\n",
      "通义千问\n",
      "。\n",
      "\n",
      "完整内容为：我是来自阿里云的大规模语言模型，我叫通义千问。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你是谁？'}\n",
    "        ],\n",
    "    stream=True\n",
    "    )\n",
    "full_content = \"\"\n",
    "print(\"流式输出内容为：\")\n",
    "for chunk in completion:\n",
    "    full_content += chunk.choices[0].delta.content\n",
    "    print(chunk.choices[0].delta.content)\n",
    "print(f\"完整内容为：{full_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是来自阿里云的大规模语言模型，我叫通义千问。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "import platform\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    response = await client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": \"你是谁\"}],\n",
    "        model=\"qwen-plus\",\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: 我是通义千问，由阿里云开发的AI助手。我被设计用来回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\n",
      "Response 2: 我是通义千问，由阿里云开发的AI助手。我被设计用来回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\n",
      "Response 3: 我是通义千问，由阿里云开发的AI助手。我被设计用来回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\n",
      "Response 4: 我是通义千问，由阿里云开发的人工智能助手。我被设计用来回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\n",
      "Response 5: 我是通义千问，由阿里云开发的AI助手。我被设计用来回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\n",
      "Total Time (Sync): 10.51 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "def main_sync():\n",
    "    start_time = time.time()\n",
    "    for i in range(5):  # Simulate 5 requests\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Request {i+1}: 你是谁\"}],\n",
    "            model=\"qwen2-72b-instruct\",\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        print(f\"Response {i+1}: {response.choices[0].message.content}\")\n",
    "    print(f\"Total Time (Sync): {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "main_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: 我是来自阿里云的大规模语言模型，我叫通义千问。\n",
      "Response 3: 我是来自阿里云的大规模语言模型，我叫通义千问。\n",
      "Response 2: 我是阿里云开发的一款超大规模语言模型，我叫通义千问。\n",
      "Response 5: 我是来自阿里云的大规模语言模型，我叫通义千问。\n",
      "Response 4: 我是通义千问，由阿里云开发的AI助手。我被设计用来回答各种问题、提供信息和与用户进行对话。有什么我可以帮助你的吗？\n",
      "Total Time (Async): 2.61 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "async def make_request(i):\n",
    "    response = await client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Request {i+1}: 你是谁\"}],\n",
    "        model=\"qwen-plus\",\n",
    "        top_p=1,\n",
    "    )\n",
    "    print(f\"Response {i+1}: {response.choices[0].message.content}\")\n",
    "\n",
    "async def main_async():\n",
    "    start_time = time.time()\n",
    "    await asyncio.gather(*[make_request(i) for i in range(5)])  # Run all requests concurrently\n",
    "    print(f\"Total Time (Async): {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "await main_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "audio = np.linspace(0, 1, 10)\n",
    "audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
